# job settings
job_script="./scripts/distributed/infer.sh"

# task settings
model=UnifiedTransformer
task=DialogGeneration

vocab_path="./projects/DSTC9-Track1/vocab.txt"
spm_model_file="./package/dialog_en/spm.model"
infer_file="${DATA_PATH}/task3_${DATASET_TYPE}.tsv"
data_format="raw"
file_format="file"
config_path="./projects/DSTC9-Track1/32L.json"

# inference settings
init_params="${MODEL_PATH}/SU-32L"
in_tokens="false"
batch_size=2

output_name="data_id,response"

infer_args="--use_role true --position_style relative --decoding_strategy beam_search --beam_size 5 --max_src_len 256 --max_knowledge_len 128 --max_tgt_len 128 --max_dec_len 127 --max_seq_len 512"

log_dir="${OUTPUT_PATH}/task3_${DATASET_TYPE}/log"
save_path="${OUTPUT_PATH}/task3_${DATASET_TYPE}/output"
