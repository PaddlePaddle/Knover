# job settings
job_script="./scripts/distributed/infer.sh"

# task settings
model=Diamante
task=DialogGeneration

vocab_path="./projects/Diamante/conf/vocab.txt"
spm_model_file="./projects/Diamante/conf/spm.model"
config_path="./projects/Diamante/conf/11B.json"

data_format="raw"
file_format="file"
infer_file="./project/Diamante/processed_data/test.tsv"

log_dir="./projects/Diamante/log"
save_path="./projects/Diamante/output"

init_params="./projects/Diamante/output/best/"

# inference settings
in_tokens="false"
batch_size=4
output_name="response"

infer_args="
--is_cn false
--ngram_blocking 3
--ranking_score ranking_score
--max_src_len 256
--max_tgt_len 128
--max_seq_len 384
--decoding_strategy topk_sampling
--num_samples 20
--topk 10
--use_sharding true
"

export CUDA_VISIBLE_DEVICES=0,1,2,3
