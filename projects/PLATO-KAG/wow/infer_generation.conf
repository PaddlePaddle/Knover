# job settings
job_script="./scripts/distributed/infer.sh"

# task settings
model=PlatoKAG
task=KnowledgeAugmentedGeneration

vocab_path="./projects/PLATO-KAG/vocab.txt"
specials_path="./projects/PLATO-KAG/specials.txt"
spm_model_file="./package/dialog_en/spm.model"

infer_file="${OUTPUT_PATH}/${PHASE}_${SPLIT}/selection/output/infer_data.tsv"
data_format="raw"
file_format="file"
config_path="./projects/PLATO-KAG/wow/24L.json"

# inference settings
init_params="${MODEL_PATH}/24L_PLATO_KAG"
in_tokens="false"
batch_size=5

output_name="response"

infer_args="
--specials_path ./projects/PLATO-KAG/specials.txt
--use_role true
--position_style relative
--knowledge_position pre_src
--max_topic_len 16
--max_src_len 240
--max_seq_len 512
--max_tgt_len 128
--max_knowledge_len 128
--do_generation true
--decoding_strategy topk_sampling
--num_samples 20
--topk 10
"

log_dir="${OUTPUT_PATH}/${PHASE}_${SPLIT}/generation/log"
save_path="${OUTPUT_PATH}/${PHASE}_${SPLIT}/generation/output"