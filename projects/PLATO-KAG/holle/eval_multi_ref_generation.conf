# job settings
job_script="./scripts/distributed/infer.sh"

# task settings
model=PlatoKAG
task=KnowledgeAugmentedGeneration

vocab_path="./projects/PLATO-KAG/vocab.txt"
spm_model_file="./package/dialog_en/spm.model"

infer_file="${OUTPUT_PATH}/test/selection/output/multi_ref_infer_data.tsv"
data_format="raw"
file_format="file"
config_path="./projects/PLATO-KAG/holle/24L.json"

# evaluation settings
init_params="${MODEL_PATH}/24L_PLATO_KAG"
in_tokens="false"
batch_size=64

output_name="tokens_num,token_lm_loss,gt_response"

infer_args="
--specials_path ./projects/PLATO-KAG/specials.txt
--use_role true
--position_style relative
--knowledge_position pre_src
--max_src_len 256
--max_seq_len 512
--max_tgt_len 128
--max_knowledge_len 128
--multi_eval true
--do_generation false
--shuffle_pool_size 0
--sort_pool_size 0
"

log_dir="${OUTPUT_PATH}/test/eval_multi/log"
save_path="${OUTPUT_PATH}/test/eval_multi/output"
