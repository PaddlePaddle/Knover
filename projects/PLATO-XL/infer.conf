# job settings
job_script="./scripts/distributed/infer.sh"

# task settings
model=UnifiedTransformer
task=DialogGeneration

vocab_path="./package/dialog_en/vocab.txt"
spm_model_file="./package/dialog_en/spm.model"
config_path="./projects/PLATO-XL/11B.json"
data_format="raw"
file_format="file"

# local path
infer_file="./data/dailydialog_test_60.tsv"
init_params="./projects/PLATO-XL/models/11B"
log_dir="./projects/PLATO-XL/log"
save_path="./projects/PLATO-XL/output"
export CUDA_VISIBLE_DEVICES=0,1

# inference settings
in_tokens="false"
batch_size=2
output_name="response"

infer_args="
--use_role true
--position_style relative
--decoding_strategy topk_sampling
--topk 10
--num_samples 20
--use_sharding true
"
